{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "LR-7030-split.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sairagillani18k/AirBnb-Zillow-Price_Prediciton/blob/master/LR_7030_split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8guhzHeqF5J7"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sympy import *\n",
        "import matplotlib.pyplot as plt\n",
        "import operator\n",
        "\n",
        "from IPython.core.display import display\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data_utils\n",
        "import torch.nn.init as init\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import model_selection\n",
        "\n",
        "init_printing(use_unicode=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKoMI5adF5J_"
      },
      "source": [
        "data = pd.read_csv(\"Desktop/data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX4pO7g6F5KB"
      },
      "source": [
        "x = data.drop([\"id\", \"diagnosis\", \"Unnamed: 32\"], axis=1)\n",
        "diag = { \"M\": 1, \"B\": 0}\n",
        "y = data[\"diagnosis\"].replace(diag)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5byBWOLgF5KE"
      },
      "source": [
        "def create_model(layer_dims):\n",
        "    model = torch.nn.Sequential()\n",
        "    for idx, dim in enumerate(layer_dims):\n",
        "        if (idx < len(layer_dims) - 1):\n",
        "            module = torch.nn.Linear(dim, layer_dims[idx + 1])\n",
        "            init.xavier_normal(module.weight)\n",
        "            model.add_module(\"linear\" + str(idx), module)\n",
        "        else:\n",
        "            model.add_module(\"sig\" + str(idx), torch.nn.Sigmoid())\n",
        "        if (idx < len(layer_dims) - 2):\n",
        "            model.add_module(\"relu\" + str(idx), torch.nn.ReLU())\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0ohzjiNF5KG",
        "outputId": "3e95ca6a-5409-464c-8f47-3cd8bd08e991"
      },
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "iter = 100\n",
        "accuracy = list()\n",
        "\n",
        "for i in range(iter): # No of Iteration\n",
        "    print(\"iteration No. \", i)\n",
        "    count = 0\n",
        "    \n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=100)\n",
        "    scaler = StandardScaler()\n",
        "    transformed = scaler.fit_transform(x_train)\n",
        "\n",
        "    train = data_utils.TensorDataset(torch.from_numpy(transformed).float(),\n",
        "                                     torch.from_numpy(y_train.to_numpy()).float())\n",
        "    dataloader = data_utils.DataLoader(train, batch_size=128, shuffle=False)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    transformed = scaler.fit_transform(x_test)\n",
        "\n",
        "    test_set = torch.from_numpy(transformed).float()\n",
        "    test_valid = torch.from_numpy(y_test.to_numpy()).float()\n",
        "    \n",
        "    ## Create model and hyper parameters\n",
        "    dim_in = x_train.shape[1]\n",
        "    dim_out = 1\n",
        "\n",
        "    layer_dims = [dim_in, 20, 10, dim_out]\n",
        "\n",
        "    model = create_model(layer_dims)\n",
        "\n",
        "    loss_fn = torch.nn.MSELoss(size_average=False)\n",
        "    learning_rate = 0.0007\n",
        "    n_epochs = 10\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    ## Now run model\n",
        "    history = { \"loss\": [], \"accuracy\": [], \"loss_val\": [], \"accuracy_val\": [] }\n",
        "    for epoch in range(n_epochs):\n",
        "        loss = None\n",
        "\n",
        "        for idx, (minibatch, target) in enumerate(dataloader):\n",
        "            y_pred = model(Variable(minibatch))\n",
        "\n",
        "            loss = loss_fn(y_pred, Variable(target.float()))\n",
        "            prediction = [1 if x > 0.5 else 0 for x in y_pred.data.numpy()]\n",
        "            correct = (prediction == target.numpy()).sum()\n",
        "\n",
        "            # This can be uncommented for a per mini batch feedback\n",
        "            #history[\"loss\"].append(loss.data[0])\n",
        "            #history[\"accuracy\"].append(100 * correct / len(prediction))\n",
        "\n",
        "            y_val_pred = model(Variable(test_set))\n",
        "            loss_val = loss_fn(y_val_pred, Variable(test_valid.float()))\n",
        "            prediction_val = [1 if x > 0.5 else 0 for x in y_val_pred.data.numpy()]\n",
        "            correct_val = (prediction_val == test_valid.numpy()).sum()\n",
        "\n",
        "            # This can be uncommented for a per mini batch feedback\n",
        "            #history[\"loss_val\"].append(loss_val.data[0])\n",
        "            #history[\"accuracy_val\"].append(100 * correct_val / len(prediction_val))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        history[\"loss\"].append(loss.data)\n",
        "        history[\"accuracy\"].append(100 * correct / len(prediction))\n",
        "        history[\"loss_val\"].append(loss_val.data)\n",
        "        history[\"accuracy_val\"].append(100 * correct_val / len(prediction_val))\n",
        "\n",
        "        print(\"Loss, accuracy, val loss, val acc at epoch\", epoch + 1,history[\"loss\"][-1], \n",
        "              history[\"accuracy\"][-1], history[\"loss_val\"][-1], history[\"accuracy_val\"][-1] )\n",
        "\n",
        "\n",
        "    index, value = max(enumerate(history[\"accuracy_val\"]), key=operator.itemgetter(1))\n",
        "\n",
        "    print(\"Best accuracy was {} at iteration {}\".format(value, index))\n",
        "    accuracy.append(value)\n",
        "    print(\"accuracy is \", value)\n",
        "\n",
        "f = open(\"cross_validation.txt\", \"a+\")\n",
        "f.write(\"average cv accuracy for {0} iterations and {1} folds is \".format(iter,count) + str(np.sum(np.array(accuracy))/(iter*count)) + '\\n')\n",
        "f.write(\"standard deviation cv accuracy for {0} iterations and {1} folds is \".format(iter,count) + str(np.std(np.array(accuracy))) + '\\n')\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration No.  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(56.1617) 7.142857142857143 tensor(7995.7905) 26.31578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(54.9425) 7.142857142857143 tensor(7879.7695) 24.56140350877193\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(53.8826) 7.142857142857143 tensor(7776.3237) 22.22222222222222\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(52.8916) 7.142857142857143 tensor(7683.2251) 22.22222222222222\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(51.9404) 7.142857142857143 tensor(7599.6694) 22.80701754385965\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(50.9744) 7.142857142857143 tensor(7524.8481) 23.976608187134502\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(50.0820) 14.285714285714286 tensor(7458.9487) 26.900584795321638\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(49.2519) 14.285714285714286 tensor(7400.9609) 33.91812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(48.4722) 21.428571428571427 tensor(7350.4282) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(47.7559) 42.857142857142854 tensor(7307.8560) 47.36842105263158\n",
            "Best accuracy was 47.36842105263158 at iteration 9\n",
            "accuracy is  47.36842105263158\n",
            "iteration No.  1\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(57.8365) 35.714285714285715 tensor(8079.2886) 39.76608187134503\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(56.1750) 35.714285714285715 tensor(7905.0601) 41.52046783625731\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(54.6419) 42.857142857142854 tensor(7755.6279) 42.10526315789474\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(53.2113) 50.0 tensor(7629.2090) 43.27485380116959\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(51.9510) 50.0 tensor(7525.4297) 42.69005847953216\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(50.7808) 57.142857142857146 tensor(7442.6416) 46.78362573099415\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(49.7154) 71.42857142857143 tensor(7378.6851) 49.12280701754386\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(48.6937) 71.42857142857143 tensor(7330.4834) 52.046783625730995\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(47.7867) 57.142857142857146 tensor(7296.0854) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(47.0604) 50.0 tensor(7272.7505) 54.3859649122807\n",
            "Best accuracy was 54.3859649122807 at iteration 8\n",
            "accuracy is  54.3859649122807\n",
            "iteration No.  2\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(58.3998) 35.714285714285715 tensor(8455.6855) 52.63157894736842\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(55.6876) 35.714285714285715 tensor(8208.9814)"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 52.046783625730995\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(53.3015) 42.857142857142854 tensor(8008.3687) 53.801169590643276\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(51.2811) 50.0 tensor(7850.3955) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(49.6344) 50.0 tensor(7728.2441) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(48.3201) 50.0 tensor(7636.8296) 55.55555555555556\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(47.2405) 42.857142857142854 tensor(7567.2861) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(46.4019) 50.0 tensor(7513.0552) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(45.7392) 57.142857142857146 tensor(7471.3237) 55.55555555555556\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(45.2108) 57.142857142857146 tensor(7439.6914) 54.97076023391813\n",
            "Best accuracy was 59.64912280701754 at iteration 3\n",
            "accuracy is  59.64912280701754\n",
            "iteration No.  3\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(60.6273) 21.428571428571427 tensor(8290.8135) 31.57894736842105\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(59.2125) 21.428571428571427 tensor(8126.6528) 28.65497076023392\n",
            "Loss, accuracy, val loss, val acc at epoch 3 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(57.9715) 14.285714285714286 tensor(7987.6909) 25.730994152046783\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(56.8178) 7.142857142857143 tensor(7869.6768) 24.56140350877193\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(55.8265) 7.142857142857143 tensor(7771.1914) 25.730994152046783\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(54.9547) 7.142857142857143 tensor(7686.5142) 27.485380116959064\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(54.1374) 7.142857142857143 tensor(7613.0269) 26.900584795321638\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(53.3426) 7.142857142857143 tensor(7548.4790) 29.239766081871345\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(52.5309) 21.428571428571427 tensor(7491.3960) 33.333333333333336\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(51.7599) 21.428571428571427 tensor(7440.0718) 35.67251461988304\n",
            "Best accuracy was 35.67251461988304 at iteration 9\n",
            "accuracy is  35.67251461988304\n",
            "iteration No.  4\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(50.0322) 71.42857142857143 tensor(8085.5791) 81.28654970760233\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(48.6155) 78.57142857142857 tensor(7935.3618) 81.87134502923976\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(47.3537) 78.57142857142857 tensor(7804.3271) 80.70175438596492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(46.1797) 78.57142857142857 tensor(7689.5220) 81.28654970760233\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(45.1849) 78.57142857142857 tensor(7593.8696) 80.11695906432749\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(44.3993) 71.42857142857143 tensor(7515.2759) 76.0233918128655\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(43.8105) 78.57142857142857 tensor(7451.3452) 70.76023391812865\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.3654) 78.57142857142857 tensor(7401.9355) 67.25146198830409\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.0385) 78.57142857142857 tensor(7363.7729) 66.66666666666667\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.8098) 78.57142857142857 tensor(7336.1914) 64.32748538011695\n",
            "Best accuracy was 81.87134502923976 at iteration 1\n",
            "accuracy is  81.87134502923976\n",
            "iteration No.  5\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(43.3406) 78.57142857142857 tensor(7317.6846) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(43.1434) 78.57142857142857 tensor(7293.2041) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(43.0081) 78.57142857142857 tensor(7271.4985) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.9125) 78.57142857142857 tensor(7252.7090) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.8260) 78.57142857142857 tensor(7236.8672) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.7464) 78.57142857142857 tensor(7223.5942) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.6786) 71.42857142857143 tensor(7212.6440) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.6205) 71.42857142857143 tensor(7203.4336) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.5699) 71.42857142857143 tensor(7195.1396) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.5263) 71.42857142857143 tensor(7187.7500) 59.64912280701754\n",
            "Best accuracy was 61.40350877192982 at iteration 1\n",
            "accuracy is  61.40350877192982\n",
            "iteration No.  6\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(45.9865) 71.42857142857143 tensor(7198.8091) 54.97076023391813\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(45.5741) 78.57142857142857 tensor(7184.4951) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(45.2027) 78.57142857142857 tensor(7173.5430) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(44.8665) 78.57142857142857 tensor(7165.7505) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(44.5725) 85.71428571428571 tensor(7160.5601) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 6"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " tensor(44.3165) 78.57142857142857 tensor(7157.9585) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.0934) 78.57142857142857 tensor(7156.7705) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.9057) 78.57142857142857 tensor(7156.6353) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.7443) 78.57142857142857 tensor(7157.1118) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.6099) 78.57142857142857 tensor(7157.8438) 59.06432748538012\n",
            "Best accuracy was 59.06432748538012 at iteration 9\n",
            "accuracy is  59.06432748538012\n",
            "iteration No.  7\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(46.5882) 42.857142857142854 tensor(7400.2168) 56.14035087719298\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(45.7132) 50.0 tensor(7351.8447) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(44.9841) 57.142857142857146 tensor(7324.6841) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(44.3467) 57.142857142857146 tensor(7308.7446) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(43.8266) 64.28571428571429 tensor(7297.8818) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(43.3996) 64.28571428571429 tensor(7289.1172) 63.74269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(43.0573) 64.28571428571429 tensor(7281.8281) 63.74269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.8057) 64.28571428571429 tensor(7276.0332) 63.74269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.6195) 64.28571428571429 tensor(7270.5259) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.4978) 64.28571428571429 tensor(7264.9170) 64.32748538011695\n",
            "Best accuracy was 64.32748538011695 at iteration 8\n",
            "accuracy is  64.32748538011695\n",
            "iteration No.  8\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(59.3973) 35.714285714285715 tensor(8490.3369) 31.57894736842105\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(56.9944) 35.714285714285715 tensor(8257.8740) 30.4093567251462\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(54.6869) 42.857142857142854 tensor(8054.0776) 33.91812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(52.6230) 42.857142857142854 tensor(7874.2744) 36.25730994152047\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(50.8169) 50.0 tensor(7717.5093) 38.01169590643275\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(49.3172) 50.0 tensor(7586.3569) 42.10526315789474\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(48.0549) 78.57142857142857 tensor(7481.9316) 46.198830409356724\n",
            "Loss, accuracy, val loss, val acc at epoch 8 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(47.0750) 78.57142857142857 tensor(7401.7065) 50.292397660818715\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(46.2510) 78.57142857142857 tensor(7341.7002) 52.046783625730995\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(45.5808) 71.42857142857143 tensor(7300.2466) 56.14035087719298\n",
            "Best accuracy was 56.14035087719298 at iteration 9\n",
            "accuracy is  56.14035087719298\n",
            "iteration No.  9\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(48.6609) 64.28571428571429 tensor(7395.3711) 65.49707602339181\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(47.5046) 64.28571428571429 tensor(7323.9873) 63.74269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(46.4377) 71.42857142857143 tensor(7278.2402) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(45.5326) 71.42857142857143 tensor(7251.5928) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(44.8174) 71.42857142857143 tensor(7236.9512) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(44.2603) 71.42857142857143 tensor(7228.4282) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(43.8382) 71.42857142857143 tensor(7222.2622) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.5310) 71.42857142857143 tensor(7216.4956) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.3195) 78.57142857142857 tensor(7210.1152) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.1835) 78.57142857142857 tensor(7203.2949) 60.8187134502924\n",
            "Best accuracy was 65.49707602339181 at iteration 0\n",
            "accuracy is  65.49707602339181\n",
            "iteration No.  10\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(50.7038) 28.571428571428573 tensor(7518.5981) 30.994152046783626\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(50.0854) 28.571428571428573 tensor(7447.2080) 30.994152046783626\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(49.4633) 14.285714285714286 tensor(7384.8687) 31.57894736842105\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(48.8294) 14.285714285714286 tensor(7330.5654) 33.333333333333336\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(48.2468) 14.285714285714286 tensor(7282.4292) 36.25730994152047\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(47.7086) 28.571428571428573 tensor(7243.6875) 45.02923976608187\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(47.1063) 42.857142857142854 tensor(7215.0288) 47.953216374269005\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(46.4338) 50.0 tensor(7196.3794) 53.801169590643276\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(45.6720) 50.0 tensor(7188.9893) 53.21637426900585\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(45.0214) 57.142857142857146 tensor(7191.6055) 54.97076023391813\n",
            "Best accuracy was 54.97076023391813 at iteration 9\n",
            "accuracy is  54.97076023391813\n",
            "iteration No.  11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(48.3524) 50.0 tensor(7717.3223) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(47.0792) 50.0 tensor(7633.0117) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(46.1008) 57.142857142857146 tensor(7568.9756) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(45.3867) 57.142857142857146 tensor(7518.8696) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(44.8331) 57.142857142857146 tensor(7479.5278) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(44.4058) 57.142857142857146 tensor(7446.4834) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.0555) 64.28571428571429 tensor(7418.6729) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.7744) 64.28571428571429 tensor(7393.5098) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.5429) 64.28571428571429 tensor(7369.8408) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.3674) 64.28571428571429 tensor(7347.4648) 61.98830409356725\n",
            "Best accuracy was 61.98830409356725 at iteration 9\n",
            "accuracy is  61.98830409356725\n",
            "iteration No.  12\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(59.9358) 28.571428571428573 tensor(8398.6973) 21.05263157894737\n",
            "Loss, accuracy, val loss, val acc at epoch 2 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(57.4103) 28.571428571428573 tensor(8166.1592) 18.128654970760234\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(55.2088) 28.571428571428573 tensor(7970.9814) 17.54385964912281\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(53.5056) 28.571428571428573 tensor(7806.1089) 18.71345029239766\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(52.0297) 28.571428571428573 tensor(7672.0708) 20.46783625730994\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(50.6691) 50.0 tensor(7563.6787) 26.31578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(49.4347) 50.0 tensor(7478.0620) 30.4093567251462\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(48.2712) 50.0 tensor(7411.3901) 33.91812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(47.2939) 57.142857142857146 tensor(7358.9917) 36.8421052631579\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(46.4784) 57.142857142857146 tensor(7319.0942) 41.52046783625731\n",
            "Best accuracy was 41.52046783625731 at iteration 9\n",
            "accuracy is  41.52046783625731\n",
            "iteration No.  13\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(57.7576) 14.285714285714286 tensor(8218.1426) 27.485380116959064\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(55.4631) 14.285714285714286 tensor(7985.5479) 28.65497076023392\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(53.3048) 21.428571428571427 tensor(7782.8145) 31.57894736842105\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(51.3232) 28.571428571428573 tensor(7610.2305) 34.50292397660819\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(49.5305) 35.714285714285715 tensor(7468.0977) 34.50292397660819\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(47.9308) 50.0 tensor(7357.5317) 37.42690058479532\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(46.5942) 50.0 tensor(7276.5508) 42.10526315789474\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(45.4916) 57.142857142857146 tensor(7218.9512) 49.12280701754386\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(44.6102) 57.142857142857146 tensor(7179.5342) 53.21637426900585\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.9219) 64.28571428571429 tensor(7154.9873) 56.14035087719298\n",
            "Best accuracy was 56.14035087719298 at iteration 9\n",
            "accuracy is  56.14035087719298\n",
            "iteration No.  14\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(62.2251) 28.571428571428573 tensor(8415.7295) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(60.6774) 28.571428571428573 tensor(8218.2812) 41.52046783625731\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(59.1298) 28.571428571428573 tensor(8041.1890) 40.93567251461988\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(57.6321) 28.571428571428573 tensor(7882.5400) 40.93567251461988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(56.2283) 28.571428571428573 tensor(7741.5928) 44.44444444444444\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(54.9260) 28.571428571428573 tensor(7617.7910) 39.1812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(53.7055) 21.428571428571427 tensor(7512.7773) 38.59649122807018\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(52.5045) 35.714285714285715 tensor(7425.3911) 38.01169590643275\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(51.3594) 50.0 tensor(7355.2881) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(50.2874) 50.0 tensor(7298.4243) 45.02923976608187\n",
            "Best accuracy was 45.02923976608187 at iteration 9\n",
            "accuracy is  45.02923976608187\n",
            "iteration No.  15\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(45.7162) 57.142857142857146 tensor(7179.8901) 49.707602339181285\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(45.2736) 57.142857142857146 tensor(7156.1455) 52.046783625730995\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(44.8905) 64.28571428571429 tensor(7137.1807) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(44.5701) 71.42857142857143 tensor(7122.6050) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(44.2940) 71.42857142857143 tensor(7111.6826) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch 6 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(44.0023) 71.42857142857143 tensor(7103.3174) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(43.7324) 71.42857142857143 tensor(7097.5400) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.4888) 71.42857142857143 tensor(7093.8931) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.2621) 71.42857142857143 tensor(7091.6934) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.0554) 71.42857142857143 tensor(7090.7139) 59.64912280701754\n",
            "Best accuracy was 59.64912280701754 at iteration 6\n",
            "accuracy is  59.64912280701754\n",
            "iteration No.  16\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(44.5024) 50.0 tensor(7453.8369) 52.63157894736842\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(43.7608) 57.142857142857146 tensor(7383.0562) 53.21637426900585\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(43.2656) 64.28571428571429 tensor(7344.3887) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.9152) 64.28571428571429 tensor(7332.2432) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.6866) 71.42857142857143 tensor(7337.0474) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.5353) 71.42857142857143 tensor(7349.0913) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.4160) 71.42857142857143 tensor(7360.2549) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.3175) 71.42857142857143 tensor(7366.2759) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.2308) 71.42857142857143 tensor(7366.1504) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.1502) 71.42857142857143 tensor(7361.4424) 57.89473684210526\n",
            "Best accuracy was 59.06432748538012 at iteration 3\n",
            "accuracy is  59.06432748538012\n",
            "iteration No.  17\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(47.5425) 42.857142857142854 tensor(7672.9966) 26.31578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(46.3893) 42.857142857142854 tensor(7548.1841) 29.82456140350877\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(45.4615) 57.142857142857146 tensor(7452.9414) 37.42690058479532\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(44.7321) 57.142857142857146 tensor(7382.1406) 43.85964912280702\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(44.1835) 57.142857142857146 tensor(7329.3193) 46.78362573099415\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(43.7767) 64.28571428571429 tensor(7291.0435) 50.87719298245614\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(43.4917) 64.28571428571429 tensor(7265.1919) 53.21637426900585\n",
            "Loss, accuracy, val loss, val acc at epoch 8 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(43.2970) 64.28571428571429 tensor(7249.4868) 54.97076023391813\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.1518) 64.28571428571429 tensor(7238.9268) 54.97076023391813\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.0444) 64.28571428571429 tensor(7230.4995) 55.55555555555556\n",
            "Best accuracy was 55.55555555555556 at iteration 9\n",
            "accuracy is  55.55555555555556\n",
            "iteration No.  18\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(46.1587) 71.42857142857143 tensor(7547.7930) 72.51461988304094\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(45.2811) 78.57142857142857 tensor(7434.5859) 73.6842105263158\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(44.5397) 78.57142857142857 tensor(7345.4585) 68.42105263157895\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(43.9061) 71.42857142857143 tensor(7279.7285) 66.08187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(43.4078) 71.42857142857143 tensor(7235.4634) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(43.0140) 71.42857142857143 tensor(7208.6963) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.7085) 71.42857142857143 tensor(7194.4585) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.4975) 71.42857142857143 tensor(7187.7563) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.3362) 71.42857142857143 tensor(7183.6567) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.2104) 71.42857142857143 tensor(7180.0166) 60.8187134502924\n",
            "Best accuracy was 73.6842105263158 at iteration 1\n",
            "accuracy is  73.6842105263158\n",
            "iteration No.  19\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(42.1844) 71.42857142857143 tensor(7427.1191) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(42.2779) 71.42857142857143 tensor(7376.7871) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(42.3631) 71.42857142857143 tensor(7331.9727) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.4403) 71.42857142857143 tensor(7292.8208) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.5111) 71.42857142857143 tensor(7259.7104) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.5734) 71.42857142857143 tensor(7232.2314) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.6073) 71.42857142857143 tensor(7209.9629) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.6183) 71.42857142857143 tensor(7191.3940) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.6054) 71.42857142857143 tensor(7176.0015) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.5458) 71.42857142857143 tensor(7164.2207) 59.64912280701754\n",
            "Best accuracy was 59.64912280701754 at iteration 0\n",
            "accuracy is  59.64912280701754\n",
            "iteration No.  20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(73.4822) 28.571428571428573 tensor(10295.3594) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(70.5714) 28.571428571428573 tensor(9924.1816) 41.52046783625731\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(67.6944) 28.571428571428573 tensor(9574.0762) 42.69005847953216\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(64.9001) 28.571428571428573 tensor(9249.4551) 42.69005847953216\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(62.2377) 28.571428571428573 tensor(8951.5850) 45.02923976608187\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(59.7929) 42.857142857142854 tensor(8680.2598) 47.36842105263158\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(57.6073) 50.0 tensor(8437.3145) 51.461988304093566\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(55.6495) 50.0 tensor(8227.9951) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(53.8885) 57.142857142857146 tensor(8048.3403) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(52.3399) 64.28571428571429 tensor(7899.4380) 66.08187134502924\n",
            "Best accuracy was 66.08187134502924 at iteration 9\n",
            "accuracy is  66.08187134502924\n",
            "iteration No.  21\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(65.3304) 28.571428571428573 tensor(8716.8262) 44.44444444444444\n",
            "Loss, accuracy, val loss, val acc at epoch 2 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(63.2340) 28.571428571428573 tensor(8528.5254) 45.6140350877193\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(61.3241) 28.571428571428573 tensor(8360.7461) 48.538011695906434\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(59.5320) 35.714285714285715 tensor(8211.1719) 52.63157894736842\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(57.9045) 35.714285714285715 tensor(8078.4639) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(56.4023) 50.0 tensor(7960.9961) 66.08187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(55.0237) 57.142857142857146 tensor(7857.9839) 70.76023391812865\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(53.7134) 64.28571428571429 tensor(7766.2900) 71.34502923976608\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(52.5335) 78.57142857142857 tensor(7685.3081) 73.09941520467837\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(51.4714) 71.42857142857143 tensor(7613.1562) 72.51461988304094\n",
            "Best accuracy was 73.09941520467837 at iteration 8\n",
            "accuracy is  73.09941520467837\n",
            "iteration No.  22\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(71.9380) 28.571428571428573 tensor(9727.4258) 30.994152046783626\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(69.4663) 28.571428571428573 tensor(9448.2197) 30.4093567251462\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(67.0798) 28.571428571428573 tensor(9178.7080) 29.82456140350877\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(64.7278) 28.571428571428573 tensor(8919.2549) 29.82456140350877\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(62.4074) 28.571428571428573 tensor(8675.1357) 30.4093567251462\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(60.2699) 35.714285714285715 tensor(8446.6074) 29.82456140350877\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(58.2895) 35.714285714285715 tensor(8241.0830) 28.65497076023392\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(56.4867) 35.714285714285715 tensor(8064.1318) 32.16374269005848\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(54.8034) 57.142857142857146 tensor(7917.3418) 35.67251461988304\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(53.2591) 64.28571428571429 tensor(7798.8062) 38.59649122807018\n",
            "Best accuracy was 38.59649122807018 at iteration 9\n",
            "accuracy is  38.59649122807018\n",
            "iteration No.  23\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(51.1755) 28.571428571428573 tensor(7784.5840) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(49.7052) 35.714285714285715 tensor(7629.4390) 66.08187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(48.4001) 50.0 tensor(7501.1577) 65.49707602339181\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(47.2700) 50.0 tensor(7397.7466) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 5 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(46.2751) 57.142857142857146 tensor(7318.5054) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(45.4335) 57.142857142857146 tensor(7260.0698) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.7243) 64.28571428571429 tensor(7220.0083) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(44.1301) 64.28571428571429 tensor(7194.2407) 63.74269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.6457) 64.28571428571429 tensor(7178.9531) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.2571) 64.28571428571429 tensor(7171.3247) 61.98830409356725\n",
            "Best accuracy was 66.08187134502924 at iteration 1\n",
            "accuracy is  66.08187134502924\n",
            "iteration No.  24\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(53.0004) 92.85714285714286 tensor(8727.2852) 90.64327485380117\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(52.0076) 92.85714285714286 tensor(8540.6680) 90.64327485380117\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(50.9427) 92.85714285714286 tensor(8353.6904) 89.47368421052632\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(49.7479) 92.85714285714286 tensor(8166.9956) 85.38011695906432\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(48.5238) 92.85714285714286 tensor(7986.2241) 84.7953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(47.3014) 92.85714285714286 tensor(7815.0864) 83.04093567251462\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(46.1076) 92.85714285714286 tensor(7658.2954) 81.28654970760233\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(45.0220) 92.85714285714286 tensor(7524.1108) 77.19298245614036\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(44.0628) 92.85714285714286 tensor(7414.6143) 71.9298245614035\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.3295) 78.57142857142857 tensor(7330.8535) 69.5906432748538\n",
            "Best accuracy was 90.64327485380117 at iteration 0\n",
            "accuracy is  90.64327485380117\n",
            "iteration No.  25\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(62.4953) 35.714285714285715 tensor(8784.6211) 42.10526315789474\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(60.6199) 28.571428571428573 tensor(8583.6504) 42.10526315789474\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(58.8019) 28.571428571428573 tensor(8394.5986) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(57.0543) 35.714285714285715 tensor(8216.3115) 40.93567251461988\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(55.3895) 28.571428571428573 tensor(8048.9468) 39.1812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(53.8969) 35.714285714285715 tensor(7897.2007) 38.59649122807018\n",
            "Loss, accuracy, val loss, val acc at epoch 7 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(52.5156) 35.714285714285715 tensor(7762.2676) 37.42690058479532\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(51.2203) 28.571428571428573 tensor(7645.7495) 34.50292397660819\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(50.0503) 28.571428571428573 tensor(7545.6670) 35.08771929824562\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(48.9959) 28.571428571428573 tensor(7460.0659) 34.50292397660819\n",
            "Best accuracy was 42.10526315789474 at iteration 0\n",
            "accuracy is  42.10526315789474\n",
            "iteration No.  26\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(44.9123) 57.142857142857146 tensor(7498.0811) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(44.1330) 71.42857142857143 tensor(7432.8936) 46.78362573099415\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(43.4320) 71.42857142857143 tensor(7383.9380) 52.63157894736842\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.9038) 71.42857142857143 tensor(7350.5288) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.5003) 71.42857142857143 tensor(7331.0088) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.2372) 71.42857142857143 tensor(7320.2437) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.0761) 71.42857142857143 tensor(7314.5483) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(41.9549) 71.42857142857143 tensor(7309.1431) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(41.8652) 71.42857142857143 tensor(7302.2407) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(41.7980) 71.42857142857143 tensor(7293.2217) 59.06432748538012\n",
            "Best accuracy was 59.06432748538012 at iteration 9\n",
            "accuracy is  59.06432748538012\n",
            "iteration No.  27\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(43.3697) 78.57142857142857 tensor(7231.4004) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(43.0404) 71.42857142857143 tensor(7213.9331) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(42.7799) 71.42857142857143 tensor(7203.1753) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.5748) 71.42857142857143 tensor(7197.9126) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.4182) 71.42857142857143 tensor(7194.9604) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.3018) 71.42857142857143 tensor(7192.6572) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.2155) 71.42857142857143 tensor(7190.4990) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.1551) 71.42857142857143 tensor(7187.9795) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.1175) 71.42857142857143 tensor(7184.8359) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(42.0809) 71.42857142857143 tensor(7181.2676) 59.64912280701754\n",
            "Best accuracy was 61.40350877192982 at iteration 0\n",
            "accuracy is  61.40350877192982\n",
            "iteration No.  28\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(45.4439) 64.28571428571429 tensor(7230.5439) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(44.9467) 71.42857142857143 tensor(7215.3447) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(44.5416) 71.42857142857143 tensor(7204.2666) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(44.2068) 71.42857142857143 tensor(7195.2935) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(43.9510) 71.42857142857143 tensor(7187.1694) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(43.7342) 71.42857142857143 tensor(7179.5015) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(43.5494) 71.42857142857143 tensor(7172.2476) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.3935) 71.42857142857143 tensor(7165.1406) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.2582) 71.42857142857143 tensor(7157.2354) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.1406) 71.42857142857143 tensor(7150.3374) 60.23391812865497\n",
            "Best accuracy was 64.32748538011695 at iteration 0\n",
            "accuracy is  64.32748538011695\n",
            "iteration No.  29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(45.3919) 71.42857142857143 tensor(7197.9077) 67.83625730994152\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(44.9865) 71.42857142857143 tensor(7183.1772) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(44.6382) 64.28571428571429 tensor(7174.0054) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(44.3360) 64.28571428571429 tensor(7168.4048) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(44.0717) 64.28571428571429 tensor(7165.6641) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(43.8385) 64.28571428571429 tensor(7164.7456) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(43.6424) 64.28571428571429 tensor(7164.6626) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.4830) 64.28571428571429 tensor(7164.6650) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.3511) 64.28571428571429 tensor(7164.5376) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.2405) 64.28571428571429 tensor(7163.9341) 59.64912280701754\n",
            "Best accuracy was 67.83625730994152 at iteration 0\n",
            "accuracy is  67.83625730994152\n",
            "iteration No.  30\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(58.7077) 35.714285714285715 tensor(8667.9062) 42.10526315789474\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(56.5788) 42.857142857142854 tensor(8433.5332) 49.707602339181285\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(54.6343) 35.714285714285715 tensor(8226.2432) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(52.9116) 50.0 tensor(8045.2305) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(51.3792) 57.142857142857146 tensor(7889.2983) 67.83625730994152\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(50.0819) 57.142857142857146 tensor(7753.7256) 72.51461988304094\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(48.9967) 71.42857142857143 tensor(7637.6753) 73.09941520467837\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(48.0753) 64.28571428571429 tensor(7540.3047) 74.26900584795321\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(47.2509) 71.42857142857143 tensor(7458.5405) 74.26900584795321\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(46.5327) 78.57142857142857 tensor(7390.3057) 76.0233918128655\n",
            "Best accuracy was 76.0233918128655 at iteration 9\n",
            "accuracy is  76.0233918128655\n",
            "iteration No.  31\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(42.3140) 71.42857142857143 tensor(7337.9482) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(42.4744) 71.42857142857143 tensor(7292.2168) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 3 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(42.6299) 71.42857142857143 tensor(7255.6831) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.7628) 71.42857142857143 tensor(7228.4917) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.8539) 71.42857142857143 tensor(7209.3354) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.8959) 71.42857142857143 tensor(7196.0957) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.8928) 71.42857142857143 tensor(7187.0347) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.8525) 71.42857142857143 tensor(7180.9351) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.7861) 71.42857142857143 tensor(7177.1055) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.7047) 71.42857142857143 tensor(7174.7129) 60.8187134502924\n",
            "Best accuracy was 61.98830409356725 at iteration 1\n",
            "accuracy is  61.98830409356725\n",
            "iteration No.  32\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(52.0064) 78.57142857142857 tensor(7914.5049) 73.09941520467837\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(50.8319) 78.57142857142857 tensor(7776.6128) 73.09941520467837\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(49.9729) 78.57142857142857 tensor(7653.1372) 73.6842105263158\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(49.1537) 71.42857142857143 tensor(7545.0649) 74.85380116959064\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(48.4054) 78.57142857142857 tensor(7447.5942) 75.43859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(47.7064) 78.57142857142857 tensor(7363.6211) 74.85380116959064\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(47.0555) 78.57142857142857 tensor(7295.2085) 73.09941520467837\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(46.4732) 78.57142857142857 tensor(7241.3608) 66.66666666666667\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(45.9557) 78.57142857142857 tensor(7203.0713) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(45.5038) 78.57142857142857 tensor(7176.1138) 59.64912280701754\n",
            "Best accuracy was 75.43859649122807 at iteration 4\n",
            "accuracy is  75.43859649122807\n",
            "iteration No.  33\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(75.2803) 28.571428571428573 tensor(10287.3369) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(71.8721) 28.571428571428573 tensor(9868.3730) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(68.7716) 28.571428571428573 tensor(9472.8984) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(65.8909) 35.714285714285715 tensor(9113.0547) 39.76608187134503\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(63.1137) 35.714285714285715 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(8791.5400) 41.52046783625731\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(60.4270) 28.571428571428573 tensor(8510.6797) 43.27485380116959\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(57.9189) 35.714285714285715 tensor(8275.7822) 46.198830409356724\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(55.6912) 35.714285714285715 tensor(8090.4399) 46.198830409356724\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(53.8188) 35.714285714285715 tensor(7943.5981) 49.12280701754386\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(52.2226) 42.857142857142854 tensor(7830.2476) 52.63157894736842\n",
            "Best accuracy was 52.63157894736842 at iteration 9\n",
            "accuracy is  52.63157894736842\n",
            "iteration No.  34\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(66.2457) 42.857142857142854 tensor(9150.9883) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(63.7642) 42.857142857142854 tensor(8931.0283) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(61.2525) 50.0 tensor(8722.1465) 64.91228070175438\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(58.7400) 57.142857142857146 tensor(8522.0781) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(56.5417) 57.142857142857146 tensor(8325.5332) 63.74269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(54.4885) 71.42857142857143 tensor(8140.5610) 63.74269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(52.5547) 71.42857142857143 tensor(7964.0991) 64.91228070175438\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(50.9748) 71.42857142857143 tensor(7805.2573) 65.49707602339181\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(49.5678) 78.57142857142857 tensor(7678.5972) 67.25146198830409\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(48.3405) 78.57142857142857 tensor(7582.9595) 66.66666666666667\n",
            "Best accuracy was 67.25146198830409 at iteration 8\n",
            "accuracy is  67.25146198830409\n",
            "iteration No.  35\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(84.2152) 28.571428571428573 tensor(12292.1689) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(81.1185) 28.571428571428573 tensor(11889.2256) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(78.0824) 28.571428571428573 tensor(11485.1182) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(75.0765) 28.571428571428573 tensor(11081.5820) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(72.0956) 28.571428571428573 tensor(10685.7227) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(69.2579) 28.571428571428573 tensor(10302.9824) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(66.8593) 28.571428571428573 tensor(9937.9082) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 8 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(64.7217) 28.571428571428573 tensor(9592.6445) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(62.6794) 28.571428571428573 tensor(9273.3955) 39.76608187134503\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(60.7861) 28.571428571428573 tensor(8986.1582) 39.1812865497076\n",
            "Best accuracy was 40.35087719298246 at iteration 0\n",
            "accuracy is  40.35087719298246\n",
            "iteration No.  36\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(43.4885) 85.71428571428571 tensor(7506.3750) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(43.3157) 85.71428571428571 tensor(7451.6245) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(43.2112) 85.71428571428571 tensor(7403.9351) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(43.1353) 85.71428571428571 tensor(7364.3203) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(43.0794) 85.71428571428571 tensor(7331.8701) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(43.0374) 85.71428571428571 tensor(7306.5703) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.9952) 85.71428571428571 tensor(7287.5527) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.9287) 85.71428571428571 tensor(7273.0029) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.8624) 85.71428571428571 tensor(7260.8047) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.8105) 78.57142857142857 tensor(7250.6865) 61.98830409356725\n",
            "Best accuracy was 62.57309941520468 at iteration 4\n",
            "accuracy is  62.57309941520468\n",
            "iteration No.  37\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(49.2051) 85.71428571428571 tensor(7517.4233) 71.9298245614035\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(48.0696) 78.57142857142857 tensor(7417.3223) 68.42105263157895\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(47.0897) 78.57142857142857 tensor(7342.4912) 70.17543859649123\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(46.2578) 92.85714285714286 tensor(7287.0054) 67.25146198830409\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(45.5644) 85.71428571428571 tensor(7249.1616) 67.83625730994152\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(44.9870) 78.57142857142857 tensor(7225.8618) 65.49707602339181\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.5150) 78.57142857142857 tensor(7213.2485) 63.74269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(44.1496) 78.57142857142857 tensor(7207.2881) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.8763) 78.57142857142857 tensor(7204.9360) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.6829) 78.57142857142857 tensor(7203.2842) 59.06432748538012\n",
            "Best accuracy was 71.9298245614035 at iteration 0\n",
            "accuracy is  71.9298245614035\n",
            "iteration No.  38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(53.7156) 50.0 tensor(7849.7173) 64.91228070175438\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(52.5169) 64.28571428571429 tensor(7725.2480) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(51.4743) 71.42857142857143 tensor(7623.4917) 64.91228070175438\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(50.5345) 78.57142857142857 tensor(7544.4175) 70.17543859649123\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(49.7144) 78.57142857142857 tensor(7484.8340) 67.25146198830409\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(48.9560) 71.42857142857143 tensor(7441.4858) 69.00584795321637\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(48.2773) 71.42857142857143 tensor(7410.2017) 66.66666666666667\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(47.7042) 78.57142857142857 tensor(7387.6270) 64.91228070175438\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(47.2114) 78.57142857142857 tensor(7371.7837) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(46.7825) 71.42857142857143 tensor(7360.9731) 64.91228070175438\n",
            "Best accuracy was 70.17543859649123 at iteration 3\n",
            "accuracy is  70.17543859649123\n",
            "iteration No.  39\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(46.7320) 50.0 tensor(7341.6748) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 2 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(46.0900) 50.0 tensor(7314.5464) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(45.5884) 50.0 tensor(7294.2808) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(45.1820) 57.142857142857146 tensor(7279.2104) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(44.8390) 64.28571428571429 tensor(7268.2212) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(44.5418) 64.28571428571429 tensor(7259.5854) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.3063) 64.28571428571429 tensor(7252.5454) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(44.1047) 64.28571428571429 tensor(7246.3418) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.9483) 64.28571428571429 tensor(7240.4883) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.8246) 64.28571428571429 tensor(7234.9800) 60.8187134502924\n",
            "Best accuracy was 60.8187134502924 at iteration 9\n",
            "accuracy is  60.8187134502924\n",
            "iteration No.  40\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(42.2807) 71.42857142857143 tensor(7155.7163) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(41.9035) 71.42857142857143 tensor(7156.7793) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(41.6376) 71.42857142857143 tensor(7157.0996) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(41.4517) 71.42857142857143 tensor(7156.2251) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(41.3226) 71.42857142857143 tensor(7153.7681) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(41.2427) 71.42857142857143 tensor(7150.2119) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(41.2044) 71.42857142857143 tensor(7145.6934) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(41.2001) 71.42857142857143 tensor(7140.6084) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(41.2064) 71.42857142857143 tensor(7135.4302) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(41.2177) 71.42857142857143 tensor(7130.5283) 59.64912280701754\n",
            "Best accuracy was 59.64912280701754 at iteration 0\n",
            "accuracy is  59.64912280701754\n",
            "iteration No.  41\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(48.1105) 50.0 tensor(7683.3774) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(47.5694) 57.142857142857146 tensor(7633.2471) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(47.1878) 57.142857142857146 tensor(7586.7471) 66.08187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 4 tensor(46.8915) 57.142857142857146 tensor(7543.9932) 64.91228070175438\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(46.6534) 57.142857142857146 tensor(7502.0161) 65.49707602339181\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(46.4654) 57.142857142857146 tensor(7461.2588) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(46.3186) 57.142857142857146 tensor(7419.2402) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(46.2046) 57.142857142857146 tensor(7387.5020) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(46.0926) 57.142857142857146 tensor(7369.7480) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(45.9039) 57.142857142857146 tensor(7358.8623) 59.06432748538012\n",
            "Best accuracy was 66.08187134502924 at iteration 2\n",
            "accuracy is  66.08187134502924\n",
            "iteration No.  42\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(51.1777) 42.857142857142854 tensor(7826.4980) 21.05263157894737\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(49.8581) 50.0 tensor(7713.8276) 25.146198830409357\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(48.6962) 50.0 tensor(7620.3247) 28.07017543859649\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(47.7197) 50.0 tensor(7543.3511) 32.748538011695906\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(46.8666) 64.28571428571429 tensor(7480.7261) 36.8421052631579\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(46.1280) 64.28571428571429 tensor(7428.6348) 43.85964912280702\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(45.5028) 64.28571428571429 tensor(7388.8408) 45.02923976608187\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(44.9872) 64.28571428571429 tensor(7359.9380) 47.953216374269005\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(44.5635) 71.42857142857143 tensor(7339.5732) 49.707602339181285\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(44.2161) 71.42857142857143 tensor(7324.7515) 51.461988304093566\n",
            "Best accuracy was 51.461988304093566 at iteration 9\n",
            "accuracy is  51.461988304093566\n",
            "iteration No.  43\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(53.3830) 42.857142857142854 tensor(7523.9780) 47.36842105263158\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(52.2164) 42.857142857142854 tensor(7427.2368) 53.21637426900585\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(50.9743) 57.142857142857146 tensor(7347.2363) 53.801169590643276\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(49.6525) 64.28571428571429 tensor(7285.3970) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(48.5173) 64.28571428571429 tensor(7243.5518) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(47.5934) 57.142857142857146 tensor(7218.0039) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 7 tensor(46.8301) 57.142857142857146 tensor(7205.4609) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(46.2169) 64.28571428571429 tensor(7200.6616) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(45.7338) 71.42857142857143 tensor(7200.1421) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(45.3493) 71.42857142857143 tensor(7200.9312) 61.40350877192982\n",
            "Best accuracy was 61.40350877192982 at iteration 9\n",
            "accuracy is  61.40350877192982\n",
            "iteration No.  44\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(51.9911) 57.142857142857146 tensor(7746.5615) 36.8421052631579\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(51.0806) 57.142857142857146 tensor(7620.9448) 39.1812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(50.3534) 64.28571428571429 tensor(7520.9717) 43.85964912280702\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(49.6533) 57.142857142857146 tensor(7439.0327) 45.02923976608187\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(48.9969) 64.28571428571429 tensor(7376.8032) 48.538011695906434\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(48.3824) 64.28571428571429 tensor(7329.5034) 51.461988304093566\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(47.8212) 71.42857142857143 tensor(7293.1162) 55.55555555555556\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(47.3446) 57.142857142857146 tensor(7264.9067) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(46.9247) 57.142857142857146 tensor(7240.6230) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(46.5384) 57.142857142857146 tensor(7219.3018) 64.32748538011695\n",
            "Best accuracy was 64.32748538011695 at iteration 9\n",
            "accuracy is  64.32748538011695\n",
            "iteration No.  45\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(41.8184) 71.42857142857143 tensor(7447.9307) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(41.9091) 71.42857142857143 tensor(7362.3477) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(42.0257) 71.42857142857143 tensor(7293.2759) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.1468) 71.42857142857143 tensor(7240.0889) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.2431) 71.42857142857143 tensor(7201.8228) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.3035) 71.42857142857143 tensor(7176.1006) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.3163) 71.42857142857143 tensor(7159.9604) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.2817) 71.42857142857143 tensor(7150.7324) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(42.2136) 71.42857142857143 tensor(7146.2632) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.1249) 71.42857142857143 tensor(7144.8857) 60.23391812865497\n",
            "Best accuracy was 60.8187134502924 at iteration 0\n",
            "accuracy is  60.8187134502924\n",
            "iteration No.  46\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(47.8989) 64.28571428571429 tensor(7828.8901) 66.08187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(46.9479) 71.42857142857143 tensor(7717.0854) 67.25146198830409\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(46.1327) 71.42857142857143 tensor(7624.6426) 69.00584795321637\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(45.4224) 71.42857142857143 tensor(7549.7266) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(44.8474) 78.57142857142857 tensor(7488.8311) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(44.3966) 78.57142857142857 tensor(7441.0469) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.0500) 85.71428571428571 tensor(7404.1538) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.7847) 85.71428571428571 tensor(7373.8877) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.5857) 85.71428571428571 tensor(7348.7852) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 10 tensor(43.4432) 78.57142857142857 tensor(7327.6353) 61.40350877192982\n",
            "Best accuracy was 69.00584795321637 at iteration 2\n",
            "accuracy is  69.00584795321637\n",
            "iteration No.  47\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(50.5501) 35.714285714285715 tensor(7789.5811) 44.44444444444444\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(49.0186) 57.142857142857146 tensor(7649.4937) 52.046783625730995\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(47.8258) 64.28571428571429 tensor(7540.3818) 52.046783625730995\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(46.8674) 64.28571428571429 tensor(7457.3936) 55.55555555555556\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(46.0349) 64.28571428571429 tensor(7394.1948) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(45.3395) 78.57142857142857 tensor(7347.4141) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.7680) 78.57142857142857 tensor(7311.9160) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(44.3018) 71.42857142857143 tensor(7285.2256) 63.74269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.9310) 71.42857142857143 tensor(7266.2070) 65.49707602339181\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.6714) 71.42857142857143 tensor(7253.1748) 64.91228070175438\n",
            "Best accuracy was 65.49707602339181 at iteration 8\n",
            "accuracy is  65.49707602339181\n",
            "iteration No.  48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(43.1166) 71.42857142857143 tensor(7273.8057) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(43.0182) 71.42857142857143 tensor(7238.4321) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(42.9375) 71.42857142857143 tensor(7209.4346) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.8694) 71.42857142857143 tensor(7186.1572) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.8029) 71.42857142857143 tensor(7168.1792) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.7440) 71.42857142857143 tensor(7154.5864) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.6893) 71.42857142857143 tensor(7144.3096) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.6358) 71.42857142857143 tensor(7136.5459) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.5837) 71.42857142857143 tensor(7130.6895) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.5347) 71.42857142857143 tensor(7126.1982) 59.64912280701754\n",
            "Best accuracy was 63.1578947368421 at iteration 0\n",
            "accuracy is  63.1578947368421\n",
            "iteration No.  49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(50.1874) 57.142857142857146 tensor(7613.6685) 45.6140350877193\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(48.8911) 64.28571428571429 tensor(7514.9722) 49.12280701754386\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(47.8350) 64.28571428571429 tensor(7437.8843) 56.14035087719298\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(46.8498) 71.42857142857143 tensor(7378.1875) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(46.0116) 64.28571428571429 tensor(7332.0908) 64.91228070175438\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(45.3026) 64.28571428571429 tensor(7298.4688) 65.49707602339181\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.6763) 64.28571428571429 tensor(7275.7998) 65.49707602339181\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(44.1495) 64.28571428571429 tensor(7262.3281) 63.74269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.7311) 78.57142857142857 tensor(7256.0107) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.3964) 71.42857142857143 tensor(7254.6030) 61.40350877192982\n",
            "Best accuracy was 65.49707602339181 at iteration 5\n",
            "accuracy is  65.49707602339181\n",
            "iteration No.  50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(47.2869) 57.142857142857146 tensor(7439.2246) 51.461988304093566\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(46.6625) 57.142857142857146 tensor(7364.3462) 52.046783625730995\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(46.1235) 57.142857142857146 tensor(7310.5815) 52.046783625730995\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(45.6649) 57.142857142857146 tensor(7270.9136) 54.97076023391813\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(45.3112) 64.28571428571429 tensor(7239.7124) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(45.0145) 64.28571428571429 tensor(7216.5229) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.7480) 71.42857142857143 tensor(7199.0103) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(44.5132) 71.42857142857143 tensor(7184.9839) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(44.2997) 71.42857142857143 tensor(7172.9976) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(44.1015) 71.42857142857143 tensor(7162.5649) 60.23391812865497\n",
            "Best accuracy was 60.23391812865497 at iteration 9\n",
            "accuracy is  60.23391812865497\n",
            "iteration No.  51\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(52.4390) 21.428571428571427 tensor(7808.3320) 36.25730994152047\n",
            "Loss, accuracy, val loss, val acc at epoch 2 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(51.0213) 35.714285714285715 tensor(7679.2061) 38.01169590643275\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(49.7255) 35.714285714285715 tensor(7568.3115) 38.59649122807018\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(48.5241) 42.857142857142854 tensor(7474.5674) 43.27485380116959\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(47.4388) 50.0 tensor(7396.9648) 48.538011695906434\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(46.5111) 57.142857142857146 tensor(7333.4814) 53.801169590643276\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(45.6889) 57.142857142857146 tensor(7282.7114) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(44.9842) 64.28571428571429 tensor(7243.1367) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(44.3792) 64.28571428571429 tensor(7213.5522) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.8543) 71.42857142857143 tensor(7192.0903) 59.64912280701754\n",
            "Best accuracy was 61.98830409356725 at iteration 7\n",
            "accuracy is  61.98830409356725\n",
            "iteration No.  52\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(46.1234) 64.28571428571429 tensor(7700.9351) 67.83625730994152\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(45.2413) 64.28571428571429 tensor(7623.0815) 68.42105263157895\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(44.4439) 64.28571428571429 tensor(7563.6558) 66.66666666666667\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(43.7824) 64.28571428571429 tensor(7515.8682) 65.49707602339181\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(43.2605) 57.142857142857146 tensor(7475.4541) 66.08187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.8562) 57.142857142857146 tensor(7440.9448) 64.91228070175438\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.5418) 64.28571428571429 tensor(7410.8750) 64.91228070175438\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.3041) 64.28571428571429 tensor(7384.0103) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.1305) 71.42857142857143 tensor(7360.2793) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.0010) 71.42857142857143 tensor(7339.8252) 62.57309941520468\n",
            "Best accuracy was 68.42105263157895 at iteration 1\n",
            "accuracy is  68.42105263157895\n",
            "iteration No.  53\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(43.9655) 50.0 tensor(7416.9478) 55.55555555555556\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(43.3297) 64.28571428571429 tensor(7362.0688) 55.55555555555556\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(42.8619) 64.28571428571429 tensor(7319.1177) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.5097) 64.28571428571429 tensor(7288.4321) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 5 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(42.2769) 64.28571428571429 tensor(7265.0376) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.1318) 64.28571428571429 tensor(7245.7622) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.0826) 64.28571428571429 tensor(7229.1396) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.0704) 64.28571428571429 tensor(7214.6074) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.0771) 64.28571428571429 tensor(7201.6030) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.0930) 71.42857142857143 tensor(7189.9536) 59.64912280701754\n",
            "Best accuracy was 59.64912280701754 at iteration 7\n",
            "accuracy is  59.64912280701754\n",
            "iteration No.  54\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(44.5451) 71.42857142857143 tensor(7266.4526) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(44.1229) 71.42857142857143 tensor(7247.1509) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(43.7773) 71.42857142857143 tensor(7234.2642) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(43.4996) 71.42857142857143 tensor(7225.3496) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(43.2752) 71.42857142857143 tensor(7217.7373) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(43.0924) 71.42857142857143 tensor(7210.0420) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.9441) 71.42857142857143 tensor(7202.1245) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.8221) 71.42857142857143 tensor(7194.1875) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.7145) 71.42857142857143 tensor(7186.9102) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.6182) 71.42857142857143 tensor(7180.4199) 58.47953216374269\n",
            "Best accuracy was 62.57309941520468 at iteration 0\n",
            "accuracy is  62.57309941520468\n",
            "iteration No.  55\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(56.2088) 85.71428571428571 tensor(8970.9648) 85.96491228070175\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(54.9924) 92.85714285714286 tensor(8796.3447) 87.71929824561404\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(53.7851) 92.85714285714286 tensor(8618.1992) 88.30409356725146\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(52.5623) 92.85714285714286 tensor(8435.2754) 87.71929824561404\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(51.3151) 92.85714285714286 tensor(8248.6172) 87.13450292397661\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(49.9858) 85.71428571428571 tensor(8061.9951) 85.38011695906432\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(48.6895) 85.71428571428571 tensor(7880.1694) 84.21052631578948\n",
            "Loss, accuracy, val loss, val acc at epoch 8 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(47.2585) 85.71428571428571 tensor(7711.4961) 83.62573099415205\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(45.8848) 78.57142857142857 tensor(7564.7388) 80.11695906432749\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(44.7175) 78.57142857142857 tensor(7442.0928) 78.3625730994152\n",
            "Best accuracy was 88.30409356725146 at iteration 2\n",
            "accuracy is  88.30409356725146\n",
            "iteration No.  56\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(54.8363) 35.714285714285715 tensor(7695.0918) 31.57894736842105\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(53.0940) 35.714285714285715 tensor(7564.2920) 36.25730994152047\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(51.4957) 50.0 tensor(7476.9233) 35.67251461988304\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(50.0560) 50.0 tensor(7419.4429) 39.76608187134503\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(48.7768) 57.142857142857146 tensor(7381.1265) 45.6140350877193\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(47.6793) 64.28571428571429 tensor(7352.5762) 52.046783625730995\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(46.8188) 64.28571428571429 tensor(7330.0513) 55.55555555555556\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(46.1433) 64.28571428571429 tensor(7310.9307) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(45.5518) 71.42857142857143 tensor(7295.5000) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(45.0806) 71.42857142857143 tensor(7283.0845) 60.23391812865497\n",
            "Best accuracy was 60.23391812865497 at iteration 9\n",
            "accuracy is  60.23391812865497\n",
            "iteration No.  57\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(51.5204) 21.428571428571427 tensor(7704.6460) 25.146198830409357\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(49.8934) 14.285714285714286 tensor(7566.0967) 23.976608187134502\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(48.6697) 28.571428571428573 tensor(7461.7041) 28.07017543859649\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(47.6395) 35.714285714285715 tensor(7383.6509) 32.16374269005848\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(46.8421) 50.0 tensor(7325.1948) 34.50292397660819\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(46.1993) 50.0 tensor(7281.8901) 39.76608187134503\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(45.6450) 50.0 tensor(7250.2729) 42.69005847953216\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(45.1908) 50.0 tensor(7226.5083) 46.78362573099415\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(44.7867) 71.42857142857143 tensor(7207.4287) 50.292397660818715\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(44.3737) 71.42857142857143 tensor(7192.0151) 52.046783625730995\n",
            "Best accuracy was 52.046783625730995 at iteration 9\n",
            "accuracy is  52.046783625730995\n",
            "iteration No.  58\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(48.2438) 50.0 tensor(7603.2847) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(47.0054) 50.0 tensor(7526.0464) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(46.0444) 50.0 tensor(7469.8560) 66.66666666666667\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(45.2797) 50.0 tensor(7429.4575) 67.25146198830409\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(44.6683) 50.0 tensor(7399.9717) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(44.2028) 50.0 tensor(7377.5635) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(43.8510) 50.0 tensor(7357.8071) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.5918) 50.0 tensor(7337.9751) 63.74269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.4135) 50.0 tensor(7317.2896) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.2990) 64.28571428571429 tensor(7296.3218) 63.1578947368421\n",
            "Best accuracy was 67.25146198830409 at iteration 3\n",
            "accuracy is  67.25146198830409\n",
            "iteration No.  59\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(60.1225) 57.142857142857146 tensor(8907.3984) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch 2 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(58.8614) 57.142857142857146 tensor(8720.6934) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(57.6513) 57.142857142857146 tensor(8535.6787) 66.08187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(56.4460) 57.142857142857146 tensor(8351.2188) 70.17543859649123\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(55.3420) 64.28571428571429 tensor(8171.1782) 73.09941520467837\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(54.2359) 64.28571428571429 tensor(7999.0776) 75.43859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(53.1930) 64.28571428571429 tensor(7841.8677) 80.11695906432749\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(52.1880) 71.42857142857143 tensor(7704.4429) 79.53216374269006\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(51.2508) 71.42857142857143 tensor(7596.4048) 82.45614035087719\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(50.3819) 71.42857142857143 tensor(7512.6035) 84.7953216374269\n",
            "Best accuracy was 84.7953216374269 at iteration 9\n",
            "accuracy is  84.7953216374269\n",
            "iteration No.  60\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(65.9066) 21.428571428571427 tensor(9192.7188) 39.76608187134503\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(64.3810) 21.428571428571427 tensor(8984.2910) 39.1812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(62.8731) 21.428571428571427 tensor(8792.2275) 39.1812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(61.3895) 21.428571428571427 tensor(8612.9229) 37.42690058479532\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(59.9126) 21.428571428571427 tensor(8443.7080) 33.91812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(58.5063) 14.285714285714286 tensor(8288.7715) 33.91812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(57.1772) 14.285714285714286 tensor(8147.7148) 32.748538011695906\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(55.8486) 7.142857142857143 tensor(8019.1558) 30.994152046783626\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(54.6176) 7.142857142857143 tensor(7903.1270) 28.65497076023392\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(53.5002) 14.285714285714286 tensor(7797.5874) 29.239766081871345\n",
            "Best accuracy was 39.76608187134503 at iteration 0\n",
            "accuracy is  39.76608187134503\n",
            "iteration No.  61\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(41.1689) 71.42857142857143 tensor(8102.7051) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(40.8171) 71.42857142857143 tensor(7919.1270) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(40.5585) 71.42857142857143 tensor(7749.4478) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(40.4114) 71.42857142857143 tensor(7596.5601) 59.64912280701754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(40.3820) 71.42857142857143 tensor(7468.9595) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(40.4612) 71.42857142857143 tensor(7368.3452) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(40.6177) 71.42857142857143 tensor(7299.3345) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(40.8008) 71.42857142857143 tensor(7252.4819) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(40.9475) 71.42857142857143 tensor(7221.2407) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(41.0793) 71.42857142857143 tensor(7198.4507) 59.64912280701754\n",
            "Best accuracy was 59.64912280701754 at iteration 0\n",
            "accuracy is  59.64912280701754\n",
            "iteration No.  62\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(43.6131) 78.57142857142857 tensor(7344.3247) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(43.0950) 78.57142857142857 tensor(7330.0601) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(42.7246) 78.57142857142857 tensor(7319.1685) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.4764) 78.57142857142857 tensor(7309.7681) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.3265) 71.42857142857143 tensor(7300.4785) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 6 tensor(42.2274) 71.42857142857143 tensor(7290.5293) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.1792) 71.42857142857143 tensor(7279.8428) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.1554) 71.42857142857143 tensor(7268.2891) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.1450) 71.42857142857143 tensor(7256.3628) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.1414) 71.42857142857143 tensor(7244.4604) 60.8187134502924\n",
            "Best accuracy was 61.40350877192982 at iteration 4\n",
            "accuracy is  61.40350877192982\n",
            "iteration No.  63\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(46.5436) 42.857142857142854 tensor(7354.5542) 50.87719298245614\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(45.6560) 50.0 tensor(7308.5322) 52.63157894736842\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(44.8856) 57.142857142857146 tensor(7272.4521) 53.801169590643276\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(44.2475) 57.142857142857146 tensor(7245.5444) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(43.6924) 64.28571428571429 tensor(7226.8843) 54.97076023391813\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(43.2261) 64.28571428571429 tensor(7213.9194) 56.14035087719298\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.8398) 64.28571428571429 tensor(7204.9385) 56.14035087719298\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.5300) 71.42857142857143 tensor(7199.2256) 56.14035087719298\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.2943) 71.42857142857143 tensor(7195.1270) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.1229) 71.42857142857143 tensor(7192.3950) 58.47953216374269\n",
            "Best accuracy was 58.47953216374269 at iteration 9\n",
            "accuracy is  58.47953216374269\n",
            "iteration No.  64\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(58.7696) 35.714285714285715 tensor(8524.1572) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(57.2714) 42.857142857142854 tensor(8350.7148) 36.25730994152047\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(55.8953) 35.714285714285715 tensor(8195.5840) 35.08771929824562\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(54.5742) 35.714285714285715 tensor(8057.7085) 35.67251461988304\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(53.3219) 35.714285714285715 tensor(7935.0527) 34.50292397660819\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(52.1412) 28.571428571428573 tensor(7825.9507) 33.91812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(51.0288) 28.571428571428573 tensor(7729.7002) 36.8421052631579\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(50.0436) 28.571428571428573 tensor(7645.0347) 38.59649122807018\n",
            "Loss, accuracy, val loss, val acc at epoch 9 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(49.1853) 42.857142857142854 tensor(7571.5410) 40.93567251461988\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(48.4286) 50.0 tensor(7506.8521) 44.44444444444444\n",
            "Best accuracy was 44.44444444444444 at iteration 9\n",
            "accuracy is  44.44444444444444\n",
            "iteration No.  65\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(51.3221) 42.857142857142854 tensor(7570.0439) 38.01169590643275\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(50.3878) 42.857142857142854 tensor(7484.1719) 39.1812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(49.4609) 42.857142857142854 tensor(7412.2969) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(48.5516) 50.0 tensor(7351.2573) 45.02923976608187\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(47.6310) 50.0 tensor(7298.2939) 45.02923976608187\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(46.8067) 64.28571428571429 tensor(7253.3682) 49.707602339181285\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(46.0453) 57.142857142857146 tensor(7216.4751) 52.046783625730995\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(45.3854) 57.142857142857146 tensor(7187.3550) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(44.8203) 57.142857142857146 tensor(7165.3130) 55.55555555555556\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(44.3302) 57.142857142857146 tensor(7150.5176) 57.30994152046784\n",
            "Best accuracy was 57.30994152046784 at iteration 9\n",
            "accuracy is  57.30994152046784\n",
            "iteration No.  66\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(41.4003) 71.42857142857143 tensor(7565.7559) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(41.6498) 71.42857142857143 tensor(7459.0103) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(41.9385) 71.42857142857143 tensor(7383.7910) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.1167) 71.42857142857143 tensor(7330.7109) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.2389) 71.42857142857143 tensor(7292.8237) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.3030) 71.42857142857143 tensor(7264.8506) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.3187) 71.42857142857143 tensor(7244.7334) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.2946) 71.42857142857143 tensor(7229.9248) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.2378) 71.42857142857143 tensor(7219.2178) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.1708) 71.42857142857143 tensor(7211.1675) 59.64912280701754\n",
            "Best accuracy was 60.23391812865497 at iteration 2\n",
            "accuracy is  60.23391812865497\n",
            "iteration No.  67\n",
            "Loss, accuracy, val loss, val acc at epoch 1 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(53.8648) 64.28571428571429 tensor(8117.3721) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(51.8175) 71.42857142857143 tensor(7844.4639) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(49.9182) 64.28571428571429 tensor(7619.7925) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(48.2219) 57.142857142857146 tensor(7446.1343) 66.08187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(46.7690) 57.142857142857146 tensor(7326.2178) 66.08187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(45.5396) 71.42857142857143 tensor(7251.6021) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.5742) 71.42857142857143 tensor(7214.0303) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.8990) 78.57142857142857 tensor(7200.4678) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.4003) 78.57142857142857 tensor(7199.3008) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.0390) 78.57142857142857 tensor(7204.3433) 59.06432748538012\n",
            "Best accuracy was 66.08187134502924 at iteration 3\n",
            "accuracy is  66.08187134502924\n",
            "iteration No.  68\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(60.9375) 50.0 tensor(8655.8105) 51.461988304093566\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(58.6563) 50.0 tensor(8374.9004) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 3 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(56.7979) 64.28571428571429 tensor(8138.2749) 64.91228070175438\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(55.0897) 71.42857142857143 tensor(7939.9463) 69.00584795321637\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(53.5414) 71.42857142857143 tensor(7772.0337) 74.26900584795321\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(52.1945) 71.42857142857143 tensor(7634.8345) 77.77777777777777\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(51.0370) 71.42857142857143 tensor(7527.1172) 77.19298245614036\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(50.0437) 71.42857142857143 tensor(7443.9072) 77.77777777777777\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(49.1932) 71.42857142857143 tensor(7379.0654) 77.19298245614036\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(48.4648) 71.42857142857143 tensor(7328.1543) 74.26900584795321\n",
            "Best accuracy was 77.77777777777777 at iteration 5\n",
            "accuracy is  77.77777777777777\n",
            "iteration No.  69\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(44.3567) 71.42857142857143 tensor(7336.0713) 54.97076023391813\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(43.4386) 78.57142857142857 tensor(7294.6260) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(42.8857) 71.42857142857143 tensor(7276.6758) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.5417) 71.42857142857143 tensor(7271.9180) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.3354) 71.42857142857143 tensor(7272.9961) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.2129) 71.42857142857143 tensor(7274.1436) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.1441) 71.42857142857143 tensor(7272.2144) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.1082) 71.42857142857143 tensor(7266.3418) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.0932) 71.42857142857143 tensor(7257.5596) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.0867) 71.42857142857143 tensor(7246.8911) 60.23391812865497\n",
            "Best accuracy was 60.23391812865497 at iteration 4\n",
            "accuracy is  60.23391812865497\n",
            "iteration No.  70\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(56.7922) 28.571428571428573 tensor(7952.9854) 25.146198830409357\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(54.6805) 21.428571428571427 tensor(7781.4512) 25.146198830409357\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(52.8255) 28.571428571428573 tensor(7644.5767) 28.07017543859649\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(51.2369) 28.571428571428573 tensor(7535.0610) 29.82456140350877\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(49.8853) 35.714285714285715 tensor(7448.2134) 32.748538011695906\n",
            "Loss, accuracy, val loss, val acc at epoch 6 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(48.7476) 42.857142857142854 tensor(7380.7197) 41.52046783625731\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(47.8482) 50.0 tensor(7328.6230) 46.78362573099415\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(47.1115) 50.0 tensor(7287.5249) 52.63157894736842\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(46.5188) 50.0 tensor(7255.3735) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(46.0156) 50.0 tensor(7230.2563) 53.801169590643276\n",
            "Best accuracy was 54.3859649122807 at iteration 8\n",
            "accuracy is  54.3859649122807\n",
            "iteration No.  71\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(42.9415) 71.42857142857143 tensor(7296.2549) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(42.5690) 71.42857142857143 tensor(7266.3652) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(42.3243) 71.42857142857143 tensor(7247.6421) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.1648) 71.42857142857143 tensor(7236.0356) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.0525) 71.42857142857143 tensor(7228.6436) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(41.9665) 71.42857142857143 tensor(7223.8838) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(41.8966) 71.42857142857143 tensor(7220.8750) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(41.8410) 71.42857142857143 tensor(7218.9409) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(41.7999) 71.42857142857143 tensor(7217.5474) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(41.7691) 71.42857142857143 tensor(7215.9810) 60.23391812865497\n",
            "Best accuracy was 61.40350877192982 at iteration 0\n",
            "accuracy is  61.40350877192982\n",
            "iteration No.  72\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(69.0896) 50.0 tensor(9799.9395) 47.36842105263158\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(66.5963) 50.0 tensor(9457.7646) 49.12280701754386\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(64.4056) 57.142857142857146 tensor(9135.8174) 49.707602339181285\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(62.4386) 57.142857142857146 tensor(8834.7715) 52.046783625730995\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(60.5994) 64.28571428571429 tensor(8559.0361) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(58.8668) 64.28571428571429 tensor(8310.7959) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(57.2434) 64.28571428571429 tensor(8084.4058) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 8 tensor(55.7225) 57.142857142857146 tensor(7890.8062) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(54.2920) 57.142857142857146 tensor(7728.6079) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(52.9735) 64.28571428571429 tensor(7594.8276) 58.47953216374269\n",
            "Best accuracy was 60.23391812865497 at iteration 7\n",
            "accuracy is  60.23391812865497\n",
            "iteration No.  73\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(45.1596) 64.28571428571429 tensor(7643.7275) 45.6140350877193\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(44.4611) 64.28571428571429 tensor(7576.5640) 53.21637426900585\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(43.9136) 64.28571428571429 tensor(7524.8096) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(43.4003) 64.28571428571429 tensor(7484.5093) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.9904) 64.28571428571429 tensor(7454.4805) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.7243) 64.28571428571429 tensor(7432.1294) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.5756) 64.28571428571429 tensor(7413.9751) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.5117) 64.28571428571429 tensor(7395.6611) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.4961) 64.28571428571429 tensor(7376.5078) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.5101) 64.28571428571429 tensor(7355.6343) 60.23391812865497\n",
            "Best accuracy was 60.8187134502924 at iteration 4\n",
            "accuracy is  60.8187134502924\n",
            "iteration No.  74\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(56.4580) 7.142857142857143 tensor(7772.2085) 19.883040935672515\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(54.8941) 7.142857142857143 tensor(7656.3193) 20.46783625730994\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(53.4509) 14.285714285714286 tensor(7550.8081) 22.80701754385965\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(52.0909) 21.428571428571427 tensor(7458.8306) 25.730994152046783\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(50.8627) 28.571428571428573 tensor(7383.2646) 33.91812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(49.7928) 28.571428571428573 tensor(7325.0698) 38.59649122807018\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(48.8294) 28.571428571428573 tensor(7282.0576) 41.52046783625731\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(48.0222) 35.714285714285715 tensor(7253.0693) 44.44444444444444\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(47.3495) 35.714285714285715 tensor(7235.1938) 49.707602339181285\n",
            "Loss, accuracy, val loss, val acc at epoch 10 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(46.7649) 35.714285714285715 tensor(7224.4453) 52.63157894736842\n",
            "Best accuracy was 52.63157894736842 at iteration 9\n",
            "accuracy is  52.63157894736842\n",
            "iteration No.  75\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(48.1129) 35.714285714285715 tensor(7295.2998) 43.27485380116959\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(47.2623) 42.857142857142854 tensor(7253.5752) 50.292397660818715\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(46.4871) 50.0 tensor(7221.8379) 54.97076023391813\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(45.7553) 64.28571428571429 tensor(7198.2983) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(45.0936) 64.28571428571429 tensor(7181.9805) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(44.5108) 71.42857142857143 tensor(7171.2397) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.0046) 71.42857142857143 tensor(7165.7593) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.5650) 71.42857142857143 tensor(7163.9307) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.1972) 71.42857142857143 tensor(7165.0718) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.9045) 71.42857142857143 tensor(7167.8359) 59.64912280701754\n",
            "Best accuracy was 60.23391812865497 at iteration 5\n",
            "accuracy is  60.23391812865497\n",
            "iteration No.  76\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(50.0048) 28.571428571428573 tensor(7668.8262) 38.01169590643275\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(48.5223) 28.571428571428573 tensor(7560.5444) 43.27485380116959\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(47.1939) 50.0 tensor(7470.1309) 45.6140350877193\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(46.0258) 64.28571428571429 tensor(7397.4795) 49.707602339181285\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(45.0720) 78.57142857142857 tensor(7339.7407) 55.55555555555556\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(44.3207) 78.57142857142857 tensor(7296.4604) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(43.7353) 78.57142857142857 tensor(7264.7666) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.3058) 78.57142857142857 tensor(7242.2202) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.9727) 78.57142857142857 tensor(7226.8750) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.7353) 78.57142857142857 tensor(7216.7466) 57.89473684210526\n",
            "Best accuracy was 59.64912280701754 at iteration 6\n",
            "accuracy is  59.64912280701754\n",
            "iteration No.  77\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(53.2685) 21.428571428571427 tensor(7752.6260) 42.10526315789474\n",
            "Loss, accuracy, val loss, val acc at epoch"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 2 tensor(52.0078) 21.428571428571427 tensor(7687.2432) 45.6140350877193\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(50.8772) 21.428571428571427 tensor(7633.6479) 45.6140350877193\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(49.7455) 35.714285714285715 tensor(7589.6709) 47.36842105263158\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(48.7124) 35.714285714285715 tensor(7550.2178) 47.953216374269005\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(47.7598) 50.0 tensor(7513.9351) 49.12280701754386\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(46.9894) 57.142857142857146 tensor(7482.0449) 49.707602339181285\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(46.3468) 64.28571428571429 tensor(7454.1323) 50.292397660818715\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(45.8282) 64.28571428571429 tensor(7429.8882) 50.292397660818715\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(45.4241) 64.28571428571429 tensor(7408.8999) 53.21637426900585\n",
            "Best accuracy was 53.21637426900585 at iteration 9\n",
            "accuracy is  53.21637426900585\n",
            "iteration No.  78\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(47.8861) 64.28571428571429 tensor(7370.2158) 47.36842105263158\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(47.1203) 64.28571428571429 tensor(7328.3857) 49.707602339181285\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(46.4404) 71.42857142857143 tensor(7302.3301) 50.292397660818715\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(45.8844) 71.42857142857143 tensor(7286.9194) 51.461988304093566\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(45.4279) 64.28571428571429 tensor(7279.6152) 55.55555555555556\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(45.0530) 64.28571428571429 tensor(7277.3696) 53.801169590643276\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.7764) 57.142857142857146 tensor(7276.3638) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(44.5652) 57.142857142857146 tensor(7273.7544) 55.55555555555556\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(44.4091) 57.142857142857146 tensor(7268.4390) 56.14035087719298\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(44.2920) 57.142857142857146 tensor(7260.2178) 56.72514619883041\n",
            "Best accuracy was 56.72514619883041 at iteration 9\n",
            "accuracy is  56.72514619883041\n",
            "iteration No.  79\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(57.5101) 7.142857142857143 tensor(8410.4150) 31.57894736842105\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(55.9569) 7.142857142857143 tensor(8216.2266) 30.4093567251462\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(54.5565) 14.285714285714286 tensor(8048.8926)"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 30.4093567251462\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(53.2995) 21.428571428571427 tensor(7904.2095) 30.4093567251462\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(52.1567) 28.571428571428573 tensor(7780.8652) 32.16374269005848\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(51.1231) 42.857142857142854 tensor(7672.5122) 33.91812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(50.2093) 42.857142857142854 tensor(7578.5444) 36.8421052631579\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(49.3935) 50.0 tensor(7497.6909) 37.42690058479532\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(48.6802) 50.0 tensor(7427.9614) 36.8421052631579\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(48.0272) 57.142857142857146 tensor(7368.1348) 39.76608187134503\n",
            "Best accuracy was 39.76608187134503 at iteration 9\n",
            "accuracy is  39.76608187134503\n",
            "iteration No.  80\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(49.8695) 85.71428571428571 tensor(7802.1162) 85.96491228070175\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(49.3422) 85.71428571428571 tensor(7708.5020) 83.62573099415205\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(48.6290) 85.71428571428571 tensor(7624.3696) 81.87134502923976\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(47.9575) 85.71428571428571 tensor(7549.7256) 79.53216374269006\n",
            "Loss, accuracy, val loss, val acc at epoch"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 5 tensor(47.2159) 85.71428571428571 tensor(7485.6523) 77.19298245614036\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(46.4952) 78.57142857142857 tensor(7434.4277) 75.43859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(45.8293) 78.57142857142857 tensor(7399.5005) 73.6842105263158\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(45.2533) 78.57142857142857 tensor(7374.2886) 69.00584795321637\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(44.8099) 71.42857142857143 tensor(7358.9858) 64.91228070175438\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(44.4671) 71.42857142857143 tensor(7350.4297) 63.1578947368421\n",
            "Best accuracy was 85.96491228070175 at iteration 0\n",
            "accuracy is  85.96491228070175\n",
            "iteration No.  81\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(49.2133) 64.28571428571429 tensor(7421.7749) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(48.1125) 78.57142857142857 tensor(7339.9287) 53.21637426900585\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(47.1364) 78.57142857142857 tensor(7285.8330) 51.461988304093566\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(46.3172) 71.42857142857143 tensor(7251.0181) 53.801169590643276\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(45.6575) 71.42857142857143 tensor(7228.9282) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(45.1321) 78.57142857142857 tensor(7216.3652) 55.55555555555556\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.7446) 78.57142857142857 tensor(7210.1494) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(44.4493) 78.57142857142857 tensor(7208.1943) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(44.2121) 78.57142857142857 tensor(7208.9297) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(44.0067) 78.57142857142857 tensor(7210.0845) 57.89473684210526\n",
            "Best accuracy was 59.06432748538012 at iteration 7\n",
            "accuracy is  59.06432748538012\n",
            "iteration No.  82\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(48.5633) 28.571428571428573 tensor(7374.1709) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(47.8182) 35.714285714285715 tensor(7312.7715) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(47.1101) 50.0 tensor(7264.4629) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(46.4657) 57.142857142857146 tensor(7227.2671) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(45.8968) 64.28571428571429 tensor(7198.1626) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(45.3891) 64.28571428571429 tensor(7176.6050) 65.49707602339181\n",
            "Loss, accuracy, val loss, val acc at epoch 7 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(44.9396) 64.28571428571429 tensor(7161.1455) 64.32748538011695\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(44.5521) 64.28571428571429 tensor(7150.6152) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(44.2378) 71.42857142857143 tensor(7143.8545) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.9692) 71.42857142857143 tensor(7139.6660) 62.57309941520468\n",
            "Best accuracy was 65.49707602339181 at iteration 5\n",
            "accuracy is  65.49707602339181\n",
            "iteration No.  83\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(42.2471) 71.42857142857143 tensor(7291.8325) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(42.0820) 71.42857142857143 tensor(7255.5752) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(41.9520) 71.42857142857143 tensor(7227.3979) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(41.8311) 71.42857142857143 tensor(7204.7456) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(41.7479) 71.42857142857143 tensor(7186.6108) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(41.6888) 71.42857142857143 tensor(7172.0220) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(41.6490) 71.42857142857143 tensor(7160.0771) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(41.6238) 71.42857142857143 tensor(7150.4277) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(41.6119) 71.42857142857143 tensor(7142.0679) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(41.6097) 71.42857142857143 tensor(7135.3574) 59.64912280701754\n",
            "Best accuracy was 59.64912280701754 at iteration 0\n",
            "accuracy is  59.64912280701754\n",
            "iteration No.  84\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(43.4946) 85.71428571428571 tensor(7407.1025) 66.08187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(43.3797) 85.71428571428571 tensor(7338.4277) 66.08187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(43.3419) 85.71428571428571 tensor(7286.3901) 64.91228070175438\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(43.3591) 85.71428571428571 tensor(7249.6772) 64.91228070175438\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(43.4038) 85.71428571428571 tensor(7225.3511) 63.74269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(43.4382) 85.71428571428571 tensor(7210.3623) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(43.4474) 78.57142857142857 tensor(7201.1797) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.3986) 78.57142857142857 tensor(7195.4863) 62.57309941520468\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.3356) 78.57142857142857 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(7192.0166) 61.98830409356725\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.2680) 78.57142857142857 tensor(7190.3599) 61.40350877192982\n",
            "Best accuracy was 66.08187134502924 at iteration 0\n",
            "accuracy is  66.08187134502924\n",
            "iteration No.  85\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(49.2699) 57.142857142857146 tensor(7391.9229) 42.10526315789474\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(48.0218) 57.142857142857146 tensor(7329.9126) 46.78362573099415\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(46.9874) 57.142857142857146 tensor(7283.0386) 49.707602339181285\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(46.0810) 57.142857142857146 tensor(7250.6699) 52.046783625730995\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(45.3126) 64.28571428571429 tensor(7229.0459) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(44.7027) 64.28571428571429 tensor(7215.0264) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(44.2378) 64.28571428571429 tensor(7205.7036) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.8928) 64.28571428571429 tensor(7197.8535) 59.06432748538012\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.6335) 78.57142857142857 tensor(7190.9541) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(43.4484) 78.57142857142857 tensor(7184.5024) 59.06432748538012\n",
            "Best accuracy was 59.06432748538012 at iteration 5\n",
            "accuracy is  59.06432748538012\n",
            "iteration No.  86\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(46.9177) 28.571428571428573 tensor(7429.2417) 37.42690058479532\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(46.6741) 35.714285714285715 tensor(7363.4380) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(46.4249) 35.714285714285715 tensor(7309.5796) 43.85964912280702\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(46.1423) 42.857142857142854 tensor(7264.6128) 46.198830409356724\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(45.8294) 50.0 tensor(7227.5352) 49.707602339181285\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(45.4504) 50.0 tensor(7197.8774) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(45.0752) 57.142857142857146 tensor(7175.0889) 56.14035087719298\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(44.7279) 64.28571428571429 tensor(7157.4878) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(44.4057) 64.28571428571429 tensor(7144.9839) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(44.0863) 64.28571428571429 tensor(7137.3232) 60.8187134502924\n",
            "Best accuracy was 60.8187134502924 at iteration 9\n",
            "accuracy is  60.8187134502924\n",
            "iteration No.  87\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(59.0911) 42.857142857142854 tensor(8466.6807) 39.1812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 2 tensor(56.9678) 35.714285714285715 tensor(8249.9502) 39.76608187134503\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(55.0598) 35.714285714285715 tensor(8073.7373) 39.76608187134503\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(53.4965) 35.714285714285715 tensor(7933.6323) 39.1812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(52.1585) 42.857142857142854 tensor(7821.9043) 35.08771929824562\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(50.9752) 35.714285714285715 tensor(7731.3032) 36.8421052631579\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(49.9423) 35.714285714285715 tensor(7653.8286) 42.10526315789474\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(49.0254) 35.714285714285715 tensor(7587.6899) 46.198830409356724\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(48.1105) 35.714285714285715 tensor(7534.3989) 49.12280701754386\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(47.1691) 35.714285714285715 tensor(7491.3838) 50.87719298245614\n",
            "Best accuracy was 50.87719298245614 at iteration 9\n",
            "accuracy is  50.87719298245614\n",
            "iteration No.  88\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(50.5794) 21.428571428571427 tensor(7622.5142) 16.374269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(49.7920) 21.428571428571427 tensor(7542.9854) 21.637426900584796\n",
            "Loss, accuracy, val loss, val acc at epoch"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 3 tensor(49.0998) 21.428571428571427 tensor(7473.9971) 26.31578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(48.4711) 42.857142857142854 tensor(7415.2573) 32.748538011695906\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(47.9342) 64.28571428571429 tensor(7365.0596) 37.42690058479532\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(47.4816) 78.57142857142857 tensor(7322.5664) 43.85964912280702\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(47.1117) 78.57142857142857 tensor(7287.3677) 48.538011695906434\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(46.7895) 78.57142857142857 tensor(7258.0698) 51.461988304093566\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(46.5137) 78.57142857142857 tensor(7234.4727) 54.97076023391813\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(46.2323) 78.57142857142857 tensor(7215.3252) 56.72514619883041\n",
            "Best accuracy was 56.72514619883041 at iteration 9\n",
            "accuracy is  56.72514619883041\n",
            "iteration No.  89\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(64.9126) 7.142857142857143 tensor(8972.1357) 29.239766081871345\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(62.8177) 7.142857142857143 tensor(8747.5273) 26.900584795321638\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(60.9441) 7.142857142857143 tensor(8544.3330) 25.146198830409357\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(59.3075) 7.142857142857143 tensor(8359.7275) 25.146198830409357\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(57.7627) 7.142857142857143 tensor(8193.8721) 25.146198830409357\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(56.3089) 14.285714285714286 tensor(8045.7944) 23.976608187134502\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(54.9336) 14.285714285714286 tensor(7914.8809) 23.391812865497077\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(53.6502) 21.428571428571427 tensor(7797.0474) 25.146198830409357\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(52.4701) 28.571428571428573 tensor(7692.6333) 26.900584795321638\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(51.4161) 28.571428571428573 tensor(7601.7700) 28.07017543859649\n",
            "Best accuracy was 29.239766081871345 at iteration 0\n",
            "accuracy is  29.239766081871345\n",
            "iteration No.  90\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(45.4447) 64.28571428571429 tensor(7381.0640) 56.14035087719298\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(44.7593) 64.28571428571429 tensor(7343.2954) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 3 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(44.1701) 64.28571428571429 tensor(7311.8667) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(43.6673) 64.28571428571429 tensor(7285.2500) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(43.2810) 64.28571428571429 tensor(7263.3169) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(42.9701) 64.28571428571429 tensor(7245.2119) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.7228) 64.28571428571429 tensor(7230.2085) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.5242) 64.28571428571429 tensor(7217.3975) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.3682) 64.28571428571429 tensor(7205.9077) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.2474) 71.42857142857143 tensor(7195.8652) 59.64912280701754\n",
            "Best accuracy was 61.40350877192982 at iteration 6\n",
            "accuracy is  61.40350877192982\n",
            "iteration No.  91\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(69.5924) 28.571428571428573 tensor(9613.3574) 38.01169590643275\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(66.5241) 28.571428571428573 tensor(9229.8086) 37.42690058479532\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(63.7500) 21.428571428571427 tensor(8885.4980) 34.50292397660819\n",
            "Loss, accuracy, val loss, val acc at epoch 4 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(61.2188) 21.428571428571427 tensor(8589.0410) 31.57894736842105\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(59.0804) 14.285714285714286 tensor(8335.7969) 28.07017543859649\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(57.3360) 14.285714285714286 tensor(8125.1665) 26.31578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(55.7785) 28.571428571428573 tensor(7957.0518) 26.31578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(54.3738) 35.714285714285715 tensor(7823.3218) 26.900584795321638\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(53.1586) 35.714285714285715 tensor(7717.8462) 27.485380116959064\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(52.0901) 35.714285714285715 tensor(7635.4365) 26.31578947368421\n",
            "Best accuracy was 38.01169590643275 at iteration 0\n",
            "accuracy is  38.01169590643275\n",
            "iteration No.  92\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(59.4578) 42.857142857142854 tensor(8239.8311) 39.76608187134503\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(57.2189) 42.857142857142854 tensor(7994.2070) 43.27485380116959\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(55.2185) 50.0 tensor(7795.7056) 43.85964912280702\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(53.5422) 57.142857142857146 tensor(7640.3726) 43.27485380116959\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(52.1220) 57.142857142857146 tensor(7526.1143) 44.44444444444444\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(50.9663) 57.142857142857146 tensor(7448.3975) 41.52046783625731\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(50.0029) 50.0 tensor(7400.6724) 42.69005847953216\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(49.1819) 50.0 tensor(7373.2983) 44.44444444444444\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(48.5186) 57.142857142857146 tensor(7358.0283) 48.538011695906434\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(47.9762) 57.142857142857146 tensor(7349.4219) 48.538011695906434\n",
            "Best accuracy was 48.538011695906434 at iteration 8\n",
            "accuracy is  48.538011695906434\n",
            "iteration No.  93\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(54.1049) 28.571428571428573 tensor(7792.6104) 27.485380116959064\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(52.7248) 35.714285714285715 tensor(7683.3677) 28.65497076023392\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(51.4817) 42.857142857142854 tensor(7591.8862) 32.16374269005848\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(50.3146) 50.0 tensor(7516.4009) 30.4093567251462\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(49.2861) 50.0 tensor(7454.2256) "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "35.67251461988304\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(48.4139) 57.142857142857146 tensor(7406.3750) 42.69005847953216\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(47.6774) 64.28571428571429 tensor(7369.8633) 46.198830409356724\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(47.0244) 57.142857142857146 tensor(7341.7319) 49.707602339181285\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(46.4626) 64.28571428571429 tensor(7320.7783) 53.21637426900585\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(45.9521) 71.42857142857143 tensor(7305.3755) 56.72514619883041\n",
            "Best accuracy was 56.72514619883041 at iteration 9\n",
            "accuracy is  56.72514619883041\n",
            "iteration No.  94\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(48.5105) 42.857142857142854 tensor(7545.2627) 41.52046783625731\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(47.4420) 50.0 tensor(7475.0615) 43.85964912280702\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(46.4859) 50.0 tensor(7421.0127) 46.78362573099415\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(45.6470) 57.142857142857146 tensor(7379.5386) 52.046783625730995\n",
            "Loss, accuracy, val loss, val acc at epoch"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 5 tensor(44.9440) 57.142857142857146 tensor(7349.2432) 56.72514619883041\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(44.3605) 57.142857142857146 tensor(7328.6631) 57.30994152046784\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(43.8837) 57.142857142857146 tensor(7314.2192) 59.64912280701754\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.4964) 64.28571428571429 tensor(7303.4707) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.1719) 64.28571428571429 tensor(7294.8794) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.9102) 71.42857142857143 tensor(7287.0601) 60.23391812865497\n",
            "Best accuracy was 60.23391812865497 at iteration 7\n",
            "accuracy is  60.23391812865497\n",
            "iteration No.  95\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(47.3166) 35.714285714285715 tensor(7448.7583) 29.239766081871345\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(46.5798) 42.857142857142854 tensor(7388.3008) 31.57894736842105\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(45.8374) 50.0 tensor(7338.1128) 35.67251461988304\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(45.2092) 57.142857142857146 tensor(7297.9131) 40.35087719298246\n",
            "Loss, accuracy, val loss, val acc at epoch 5 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(44.6696) 64.28571428571429 tensor(7266.3159) 44.44444444444444\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(44.1822) 64.28571428571429 tensor(7242.8491) 46.78362573099415\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(43.7849) 64.28571428571429 tensor(7225.8311) 48.538011695906434\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.4532) 71.42857142857143 tensor(7213.2612) 51.461988304093566\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(43.1624) 71.42857142857143 tensor(7203.4873) 54.3859649122807\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.9224) 71.42857142857143 tensor(7196.8711) 54.97076023391813\n",
            "Best accuracy was 54.97076023391813 at iteration 9\n",
            "accuracy is  54.97076023391813\n",
            "iteration No.  96\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(41.9100) 71.42857142857143 tensor(7630.8398) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(41.9635) 71.42857142857143 tensor(7534.2285) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(42.0497) 71.42857142857143 tensor(7454.9727) 60.8187134502924\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(42.1523) 71.42857142857143 tensor(7390.6011) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(42.2635) 71.42857142857143 tensor(7337.6221) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 6 tensor(42.3507) 71.42857142857143 tensor(7294.3516) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(42.4008) 71.42857142857143 tensor(7259.7520) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(42.4232) 71.42857142857143 tensor(7233.4375) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.4314) 71.42857142857143 tensor(7212.4810) 61.40350877192982\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.4300) 71.42857142857143 tensor(7197.6343) 61.40350877192982\n",
            "Best accuracy was 61.40350877192982 at iteration 3\n",
            "accuracy is  61.40350877192982\n",
            "iteration No.  97\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(46.2643) 78.57142857142857 tensor(7425.8979) 73.6842105263158\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(45.4613) 71.42857142857143 tensor(7371.1680) 71.34502923976608\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(44.8071) 71.42857142857143 tensor(7326.0054) 69.5906432748538\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(44.2618) 71.42857142857143 tensor(7288.8906) 67.25146198830409\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(43.8416) 71.42857142857143 tensor(7258.3115) 63.74269005847953\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(43.5275) 71.42857142857143 tensor(7232.8452) 63.1578947368421\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(43.2931) 78.57142857142857 tensor(7211.1030) 60.23391812865497\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(43.0950) 71.42857142857143 tensor(7193.8145) 58.47953216374269\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(42.9189) 71.42857142857143 tensor(7180.4985) 57.89473684210526\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(42.7614) 71.42857142857143 tensor(7170.4238) 57.30994152046784\n",
            "Best accuracy was 73.6842105263158 at iteration 0\n",
            "accuracy is  73.6842105263158\n",
            "iteration No.  98\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(66.5396) 14.285714285714286 tensor(9151.9658) 32.748538011695906\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(63.2517) 14.285714285714286 tensor(8822.0137) 33.333333333333336\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(60.1581) 7.142857142857143 tensor(8517.9307) 32.16374269005848\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(57.2812) 7.142857142857143 tensor(8242.1406) 33.91812865497076\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(54.6587) 7.142857142857143 tensor(8001.7944) 31.57894736842105\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(52.2903) 28.571428571428573 tensor(7799.6099) 35.08771929824562\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(50.2274) 28.571428571428573 tensor(7636.0918) 38.01169590643275\n",
            "Loss, accuracy, val loss, val acc at epoch 8 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-9-25c249d58b9c>:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
            "  init.xavier_normal(module.weight)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([171])) that is different to the input size (torch.Size([171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "D:\\ananconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(48.5003) 42.857142857142854 tensor(7510.7988) 41.52046783625731\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(47.0879) 42.857142857142854 tensor(7419.4502) 46.78362573099415\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(45.9229) 50.0 tensor(7355.7559) 53.21637426900585\n",
            "Best accuracy was 53.21637426900585 at iteration 9\n",
            "accuracy is  53.21637426900585\n",
            "iteration No.  99\n",
            "Loss, accuracy, val loss, val acc at epoch 1 tensor(51.4024) 21.428571428571427 tensor(7523.2622) 37.42690058479532\n",
            "Loss, accuracy, val loss, val acc at epoch 2 tensor(50.0950) 35.714285714285715 tensor(7451.5601) 38.59649122807018\n",
            "Loss, accuracy, val loss, val acc at epoch 3 tensor(48.9459) 64.28571428571429 tensor(7398.9224) 41.52046783625731\n",
            "Loss, accuracy, val loss, val acc at epoch 4 tensor(47.9720) 64.28571428571429 tensor(7361.2402) 45.02923976608187\n",
            "Loss, accuracy, val loss, val acc at epoch 5 tensor(47.1414) 71.42857142857143 tensor(7336.3696) 46.78362573099415\n",
            "Loss, accuracy, val loss, val acc at epoch 6 tensor(46.4281) 71.42857142857143 tensor(7321.2778) 47.953216374269005\n",
            "Loss, accuracy, val loss, val acc at epoch 7 tensor(45.8120) 78.57142857142857 tensor(7313.1216) 50.87719298245614\n",
            "Loss, accuracy, val loss, val acc at epoch 8 tensor(45.2883) 78.57142857142857 tensor(7309.6211) 52.63157894736842\n",
            "Loss, accuracy, val loss, val acc at epoch 9 tensor(44.8491) 78.57142857142857 tensor(7308.8398) 52.63157894736842\n",
            "Loss, accuracy, val loss, val acc at epoch 10 tensor(44.4809) 78.57142857142857 tensor(7309.3345) 52.046783625730995\n",
            "Best accuracy was 52.63157894736842 at iteration 7\n",
            "accuracy is  52.63157894736842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-10-b4bbf517b735>:82: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  f.write(\"average cv accuracy for {0} iterations and {1} folds is \".format(iter,count) + str(np.sum(np.array(accuracy))/(iter*count)) + '\\n')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oIZtSBuF5KJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}